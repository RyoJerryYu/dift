{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e50bfe-edb9-4932-bf43-39f047bf36d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3416bb09104ca9855c14ec07b74919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'diffusers.models.unet_2d_condition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PILToTensor\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdift_sd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SDFeaturizer\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Demo\n",
      "File \u001b[0;32m~/workspace/dift/src/models/dift_sd.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Dict, List, Optional, Union\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_2d_condition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNet2DConditionModel\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DDIMScheduler\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'diffusers.models.unet_2d_condition'"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import argparse\n",
    "import gc\n",
    "import random\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import PILToTensor\n",
    "from src.models.dift_sd import SDFeaturizer\n",
    "from src.utils.visualization import Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e967e6-ca78-424d-ac69-2bc2c0bd744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf04cbe-b63d-4484-9918-7fac9f3506e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dift = SDFeaturizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829c1cf2-82a1-45ea-b284-19a055311855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can choose visualize cat or guitar\n",
    "category = random.choice(['cat', 'guitar'])\n",
    "\n",
    "print(f\"let's visualize semantic correspondence on {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f7afc-232c-4fff-83dc-c63b876ee12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if category == 'cat':\n",
    "    filelist = ['./assets/cat.png', './assets/target_cat.png', './assets/target_cat.png']\n",
    "elif category == 'guitar':\n",
    "    filelist = ['./assets/guitar.png', './assets/target_guitar.png', './assets/target_guitar.png']\n",
    "\n",
    "prompt = f'a photo of a {category}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f2c3f-8445-42c5-b31f-be438c7239d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = []\n",
    "imglist = []\n",
    "\n",
    "# decrease these two if you don't have enough RAM or GPU memory\n",
    "img_size = 768\n",
    "ensemble_size = 8\n",
    "\n",
    "for filename in filelist:\n",
    "    img = Image.open(filename).convert('RGB')\n",
    "    img = img.resize((img_size, img_size))\n",
    "    imglist.append(img)\n",
    "    img_tensor = (PILToTensor()(img) / 255.0 - 0.5) * 2\n",
    "    ft.append(dift.forward(img_tensor,\n",
    "                           prompt=prompt,\n",
    "                           ensemble_size=ensemble_size))\n",
    "ft = torch.cat(ft, dim=0)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81ae975-cce2-491d-9b6b-58412559b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = Demo(imglist, ft, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b5ef9-db57-46dc-9ad2-9758b5d573c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "left is source image, right is target image.\n",
    "you can click on the source image, and DIFT will find the corresponding\n",
    "point on the right image, mark it with red point and also plot the per-pixel \n",
    "cosine distance as heatmap.\n",
    "'''\n",
    "demo.plot_img_pairs(fig_size=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
